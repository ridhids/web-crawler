# web-crawler
web crawler

Please run the main class here. The project prints out the main website and all the links on the page. It does not crawl to the external links,
but only the ones that are in the domain i.e wiprodigital.com
The output file 'WiprowebsitesDiscovered' is all the links found through web crawl. The same approach here can be taken for finding the static content, with regular expression that
qualifies the static content on html page.

In future what can be done ?
Considering the work here I did is in 2 days with a full time job :-), I can improvise on 
1. More detailed output for end user to understand
2. Use of JSOUP/regular expression to implement static content as well
3. Create unit test cases 'JUNITS' in the project
4. Ask user for input path, where output file can be generated. End user experience is better.  

